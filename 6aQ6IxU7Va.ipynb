{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to a competition powered by AutoDSC for Data Science Challenges! By Prof. Manoel Gadi!\n",
    "\n",
    "PLEASE DO NOT RENAME THIS FILE!\n",
    "\n",
    "\n",
    "Simply run this code and start competing today in the competion: 6aQ6IxU7Va\n",
    "\n",
    "6aQ6IxU7Va details:\n",
    " - Description / Descripción: FRAUD MODELLING CHALLENGE - Predict which Credit Card Application is legitimate and which belongs to a fraudster instead.\n",
    " - Maximum number of daily attempts / Número máximo de intentos diarios: 10000\n",
    " - Creation date / Fecha de creación: 2020-06-10 11:36:52\n",
    " - Starting date / Fecha de inicio: 2023-04-10 00:00:00\n",
    " - Ending date / Fecha de fin: 2023-05-29 23:59:00\n",
    " - Minimum time between prediction submissions / Tiempo mínimo entre envíos de predicciones: 30\n",
    "\n",
    "Of couse, to win the competition you should improve the starting model! So let's get to work!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING LIBRARIES...\n",
      "LOADING DATASETS...\n"
     ]
    }
   ],
   "source": [
    "print (\"IMPORTING LIBRARIES...\")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print (\"LOADING DATASETS...\")\n",
    "try: # reading train csv from local file\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    df_train.head()\n",
    "except: # reading train csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_train = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    csv_train_content = csv_train.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__train.csv\", 'wb') as f:\n",
    "            f.write(csv_train_content)\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "\n",
    "    \n",
    "try: # reading test csv from local file\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    df_test.head()\n",
    "except: # reading test csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_test = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    csv_test_content = csv_test.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__test.csv\", 'wb') as f:\n",
    "            f.write(csv_test_content)\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>ib_var_1</th>\n",
       "      <th>ib_var_2</th>\n",
       "      <th>ib_var_3</th>\n",
       "      <th>ib_var_4</th>\n",
       "      <th>ib_var_5</th>\n",
       "      <th>ib_var_6</th>\n",
       "      <th>ib_var_7</th>\n",
       "      <th>ib_var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>if_var_73</th>\n",
       "      <th>if_var_74</th>\n",
       "      <th>if_var_75</th>\n",
       "      <th>if_var_76</th>\n",
       "      <th>if_var_77</th>\n",
       "      <th>if_var_78</th>\n",
       "      <th>if_var_79</th>\n",
       "      <th>if_var_80</th>\n",
       "      <th>if_var_81</th>\n",
       "      <th>ob_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.4634</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>7.6341</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>11.1707</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>8.0488</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5.5854</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  ib_var_1  ib_var_2  ib_var_3  ib_var_4  ib_var_5  ib_var_6  \\\n",
       "0           0   1         0         1         0         0         1         1   \n",
       "1           1   2         0         1         0         0         0         1   \n",
       "2           2   3         0         0         0         0         1         1   \n",
       "3           3   4         0         1         0         1         1         1   \n",
       "4           4   5         0         0         0         0         0         1   \n",
       "\n",
       "   ib_var_7  ib_var_8  ...  if_var_73  if_var_74  if_var_75  if_var_76  \\\n",
       "0         0         0  ...      0.800          0          6          5   \n",
       "1         0         0  ...      0.925          5          8          5   \n",
       "2         0         0  ...      0.800          3         10          6   \n",
       "3         0         0  ...      0.825          5          5          6   \n",
       "4         0         0  ...      0.800          0         11          5   \n",
       "\n",
       "   if_var_77  if_var_78  if_var_79  if_var_80  if_var_81  ob_target  \n",
       "0   0.500000     9.4634     5140.0   0.766667          1          0  \n",
       "1   0.400000     7.6341     2570.0   0.700000          4          0  \n",
       "2   0.700000    11.1707     5140.0   0.666667          2          0  \n",
       "3   0.433333     8.0488     1028.0   0.766667          3          0  \n",
       "4   0.700000     5.5854     5140.0   0.733333          3          0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>ib_var_1</th>\n",
       "      <th>ib_var_2</th>\n",
       "      <th>ib_var_3</th>\n",
       "      <th>ib_var_4</th>\n",
       "      <th>ib_var_5</th>\n",
       "      <th>ib_var_6</th>\n",
       "      <th>ib_var_7</th>\n",
       "      <th>ib_var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>if_var_73</th>\n",
       "      <th>if_var_74</th>\n",
       "      <th>if_var_75</th>\n",
       "      <th>if_var_76</th>\n",
       "      <th>if_var_77</th>\n",
       "      <th>if_var_78</th>\n",
       "      <th>if_var_79</th>\n",
       "      <th>if_var_80</th>\n",
       "      <th>if_var_81</th>\n",
       "      <th>contract_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>20-Sep-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>12.9024</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>24-Sep-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2570.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>19-Sep-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>15.5366</td>\n",
       "      <td>2056.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>20-Sep-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>17.8293</td>\n",
       "      <td>4728.799805</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2</td>\n",
       "      <td>25-Sep-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  ib_var_1  ib_var_2  ib_var_3  ib_var_4  ib_var_5  ib_var_6  \\\n",
       "0           0   1         0         1         0         0         1         0   \n",
       "1           1   2         1         0         0         0         1         1   \n",
       "2           2   3         0         0         0         0         1         1   \n",
       "3           3   4         0         1         0         1         1         1   \n",
       "4           4   5         1         0         0         1         1         1   \n",
       "\n",
       "   ib_var_7  ib_var_8  ...  if_var_73  if_var_74  if_var_75  if_var_76  \\\n",
       "0         0         0  ...      0.775        1.0       10.0       11.0   \n",
       "1         0         0  ...      0.750        0.0        8.0       10.0   \n",
       "2         0         0  ...      0.725        0.0        8.0        6.0   \n",
       "3         0         0  ...      0.925        2.0        7.0        5.0   \n",
       "4         0         0  ...      0.925        0.0       10.0        7.0   \n",
       "\n",
       "   if_var_77  if_var_78    if_var_79  if_var_80  if_var_81  contract_date  \n",
       "0   0.666667        NaN  5140.000000   0.666667          3      20-Sep-12  \n",
       "1   0.600000    12.9024  5140.000000   0.733333          0      24-Sep-12  \n",
       "2   0.700000        NaN  2570.000000   0.766667          1      19-Sep-12  \n",
       "3   0.566667    15.5366  2056.000000   0.833333          0      20-Sep-12  \n",
       "4   0.333333    17.8293  4728.799805   0.633333          2      25-Sep-12  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DOING MY TRANSFORMATIONS...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 1: DOING MY TRANSFORMATIONS...\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\")\n",
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)\n",
    "\n",
    "output_var = df_train.columns[-1]\n",
    "in_model = get_specific_columns(df_train, [\"float64\", \"int64\"], [output_var], ignore_target = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n",
      "Best Hyperparameters:\n",
      "bootstrap: False\n",
      "max_depth: 84\n",
      "max_features: sqrt\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "n_estimators: 255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=84, max_features='sqrt',\n",
       "                       n_estimators=255, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Generate a random classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters and their search space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(10, 100),\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform randomized search to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy')\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Fit the best model on the entire dataset\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Now you can use the best_model for making predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "\n",
    "#try 1. Gini: 37%\n",
    "#Model 2:XGBoost\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_clf = XGBClassifier(random_state=0)\n",
    "\n",
    "# Perform Grid Search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best XGBoost classifier\n",
    "best_xgb_clf = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "fitted_model = best_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for training and test data\n",
    "pred_train = fitted_model.predict_proba(X_train)[:, 1]\n",
    "pred_test = fitted_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "\n",
    "#try 2. Gini: 41%\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Perform oversampling using SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_clf = XGBClassifier(random_state=0)\n",
    "\n",
    "# Perform Grid Search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best XGBoost classifier\n",
    "best_xgb_clf = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the resampled training data\n",
    "fitted_model = best_xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict probabilities for training and test data\n",
    "pred_train = fitted_model.predict_proba(X_train)[:, 1]\n",
    "pred_test = fitted_model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "\n",
    "#Try 3: Genetic Algorithm\n",
    "\n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "X_train = df_train[in_model]\n",
    "y_train = df_train[output_var]\n",
    "X_test = df_test[in_model]\n",
    "\n",
    "import random\n",
    "from deap import base, creator, tools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_fitness(individual):\n",
    "    # Extract the values from the individual chromosome\n",
    "    max_depth, learning_rate, subsample = individual\n",
    "\n",
    "    # Create an XGBoost classifier with the given hyperparameters\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "    # Upsample the minority class in the training data\n",
    "    X_train_resampled, y_train_resampled = resample(X_train_scaled, y_train, n_samples=X_train_scaled.shape[0], random_state=42, stratify=y_train)\n",
    "\n",
    "    # Fit the model on the resampled training data\n",
    "    fitted_model = xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict probabilities for training data\n",
    "    y_train_pred_prob = fitted_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "    # Calculate AUC-ROC score for training data\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred_prob)\n",
    "\n",
    "    return auc_train,\n",
    "\n",
    "# Create the fitness and individual classes\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Initialize the toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Define the hyperparameter ranges\n",
    "max_depth_range = (1, 10)\n",
    "learning_rate_range = (0.01, 0.5)\n",
    "subsample_range = (0.5, 1.0)\n",
    "\n",
    "# Define the number of bits for each hyperparameter\n",
    "max_depth_bits = 4\n",
    "learning_rate_bits = 8\n",
    "subsample_bits = 8\n",
    "\n",
    "# Define the attribute generator for each hyperparameter\n",
    "toolbox.register(\"attr_max_depth\", np.random.uniform, max_depth_range[0], max_depth_range[1])\n",
    "toolbox.register(\"attr_learning_rate\", np.random.uniform, learning_rate_range[0], learning_rate_range[1])\n",
    "toolbox.register(\"attr_subsample\", np.random.uniform, subsample_range[0], subsample_range[1])\n",
    "\n",
    "# Define the individual creation operator\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_max_depth, toolbox.attr_learning_rate, toolbox.attr_subsample),\n",
    "                 n=1)\n",
    "\n",
    "# Define the population creation operator\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Register the evaluation function\n",
    "toolbox.register(\"evaluate\", evaluate_fitness)\n",
    "\n",
    "# Register the selection, crossover, and mutation operators\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create an initial population of individuals\n",
    "population = toolbox.population(n=50)\n",
    "\n",
    "# Evaluate the fitness of the entire population\n",
    "fitness_values = list(map(toolbox.evaluate, population))\n",
    "for ind, fit in zip(population, fitness_values):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# Set the number of generations and run the evolution process\n",
    "num_generations = 10\n",
    "for generation in range(num_generations):\n",
    "    print(f\"Generation {generation + 1}/{num_generations}\")\n",
    "\n",
    "    # Select the next generation's parents\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation operators\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if np.random.rand() < 0.8:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if np.random.rand() < 0.2:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluate the fitness of the invalid individuals\n",
    "    invalid_individuals = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitness_values = map(toolbox.evaluate, invalid_individuals)\n",
    "    for ind, fit in zip(invalid_individuals, fitness_values):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace the current population with the offspring\n",
    "    population[:] = offspring\n",
    "\n",
    "# Select the best individual\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "best_max_depth, best_learning_rate, best_subsample = best_individual\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = XGBClassifier(max_depth=int(best_max_depth), learning_rate=best_learning_rate,\n",
    "                            subsample=best_subsample, random_state=42)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities for test data\n",
    "y_test_pred_prob = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "print (\"STEP 4: ASSESSING THE MODEL...\")\n",
    "# CALCULATING GINI PERFORMANCE ON DEVELOPMENT SAMPLE\n",
    "\n",
    "import random\n",
    "from deap import algorithms, base, creator, tools\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create a binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10,\n",
    "                           n_redundant=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the fitness function (Gini score)\n",
    "def gini_score(y_true, y_pred):\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    gini = 2 * auc - 1\n",
    "    return gini\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_fitness(individual):\n",
    "    # Extract the selected features from the individual\n",
    "    selected_features = [index for index, feature in enumerate(individual) if feature]\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "\n",
    "    # Resample the training data\n",
    "    X_train_resampled, y_train_resampled = resample(X_train_selected, y_train, random_state=42)\n",
    "\n",
    "    # Create an XGBoost classifier\n",
    "    xgb_clf = XGBClassifier()\n",
    "\n",
    "    # Fit the model on the resampled training data\n",
    "    fitted_model = xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict probabilities for training data\n",
    "    y_train_pred = fitted_model.predict_proba(X_train_resampled)[:, 1]\n",
    "\n",
    "    # Calculate the Gini score as the fitness value\n",
    "    fitness = gini_score(y_train_resampled, y_train_pred)\n",
    "\n",
    "    return fitness,\n",
    "\n",
    "# Create the DEAP toolbox\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attribute\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attribute, n=20)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)  # Register the mate operator\n",
    "\n",
    "# Register the evaluation and mutation operators\n",
    "toolbox.register(\"evaluate\", evaluate_fitness)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "# Set up the genetic algorithm parameters\n",
    "population_size = 50\n",
    "max_generations = 10\n",
    "cxpb = 0.5\n",
    "mutpb = 0.2\n",
    "hof_size = 1\n",
    "\n",
    "# Create an initial population of individuals\n",
    "population = toolbox.population(n=population_size)\n",
    "\n",
    "# Evaluate the fitness of the entire population\n",
    "fitness_values = list(map(toolbox.evaluate, population))\n",
    "for ind, fit in zip(population, fitness_values):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# Define the hall of fame object\n",
    "hof = tools.HallOfFame(hof_size)\n",
    "\n",
    "# Perform the genetic algorithm\n",
    "for generation in range(max_generations):\n",
    "    # Apply the selection, crossover, and mutation operators\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=cxpb, mutpb=mutpb)\n",
    "\n",
    "    # Evaluate the fitness of the new offspring\n",
    "    invalid_individuals = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitness_values = map(toolbox.evaluate, invalid_individuals)\n",
    "    for ind, fit in zip(invalid_individuals, fitness_values):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace the population with the offspring\n",
    "    population[:] = offspring\n",
    "\n",
    "    # Update the hall of fame\n",
    "    hof.update(population)\n",
    "\n",
    "    # Print the current generation and best individual\n",
    "    best_individual = hof[0]\n",
    "    print(f\"Generation {generation+1}/{max_generations}\")\n",
    "    print(\"Best Individual:\", best_individual)\n",
    "    print(\"Fitness Score:\", best_individual.fitness.values[0])\n",
    "\n",
    "# Get the best individual from the hall of fame\n",
    "best_individual = hof[0]\n",
    "\n",
    "# Extract the selected features from the best individual\n",
    "selected_features = [index for index, feature in enumerate(best_individual) if feature]\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "# Train a final model using the selected features\n",
    "final_model = XGBClassifier()\n",
    "final_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "y_test_pred = final_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate the Gini score for the test data\n",
    "test_gini_score = gini_score(y_test, y_test_pred)\n",
    "print(\"Gini Score on Test Data:\", test_gini_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT IS GINI?\n",
    "* watch this video for reference: https://youtu.be/MiBUBVUC8kE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Coefficient: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gini_coefficient(y_true, y_pred):\n",
    "    # Sort the true values and predicted values in descending order\n",
    "    sorted_indices = np.argsort(y_pred)[::-1]\n",
    "    sorted_true = y_true[sorted_indices]\n",
    "    sorted_pred = y_pred[sorted_indices]\n",
    "    \n",
    "    # Calculate the cumulative sum of true values\n",
    "    cum_true = np.cumsum(sorted_true)\n",
    "    \n",
    "    # Calculate the cumulative sum of predicted values\n",
    "    cum_pred = np.cumsum(sorted_pred)\n",
    "    \n",
    "    # Calculate the Lorenz curve values\n",
    "    lorenz_curve_true = cum_true / np.sum(sorted_true)\n",
    "    lorenz_curve_pred = cum_pred / np.sum(sorted_pred)\n",
    "    \n",
    "    # Calculate the Gini coefficient\n",
    "    gini_coeff = np.sum((lorenz_curve_pred[:-1] + lorenz_curve_pred[1:]) * (lorenz_curve_true[1:] - lorenz_curve_true[:-1]))\n",
    "    \n",
    "    return gini_coeff\n",
    "\n",
    "# Example usage:\n",
    "y_true = np.array([0, 1, 0, 1, 0, 1])  # True values\n",
    "y_pred = np.array([0.2, 0.8, 0.4, 0.6, 0.1, 0.9])  # Predicted values\n",
    "\n",
    "gini_score = gini_coefficient(y_true, y_pred)\n",
    "print(\"Gini Coefficient:\", gini_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Example usage:\n",
    "y_true = [0, 1, 0, 1, 0, 1]  # True values\n",
    "y_pred = [0.2, 0.8, 0.4, 0.6, 0.1, 0.9]  # Predicted values\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
